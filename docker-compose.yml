services:
  # Infrastructure: Zookeeper & Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
    networks:
      - stream_net

  kafka-1:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_HEAP_OPTS: "-Xms512M -Xmx512M"
    command:
      - bash
      - -c
      - |
        echo "Waiting for Zookeeper..."
        while ! (echo > /dev/tcp/zookeeper/2181) >/dev/null 2>&1; do sleep 2; done
        /etc/confluent/docker/run
    deploy:
      replicas: 1
    volumes:
      - kafka_data_1:/var/lib/kafka/data
    networks:
      - stream_net

  kafka-2:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_HEAP_OPTS: "-Xms512M -Xmx512M"
    deploy:
      replicas: 1
    command:
      - bash
      - -c
      - |
        echo "Waiting for Zookeeper..."
        while ! (echo > /dev/tcp/zookeeper/2181) >/dev/null 2>&1; do sleep 2; done
        /etc/confluent/docker/run
    volumes:
      - kafka_data_2:/var/lib/kafka/data
    networks:
      - stream_net

  kafka-3:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - zookeeper
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:29094,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_HEAP_OPTS: "-Xms512M -Xmx512M"
    deploy:
      replicas: 1
    command:
      - bash
      - -c
      - |
        echo "Waiting for Zookeeper..."
        while ! (echo > /dev/tcp/zookeeper/2181) >/dev/null 2>&1; do sleep 2; done
        /etc/confluent/docker/run
    volumes:
      - kafka_data_3:/var/lib/kafka/data
    networks:
      - stream_net

  init-kafka:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      echo 'Waiting for ALL brokers to be online...'
      until nc -z kafka-1 29092 && nc -z kafka-2 29093 && nc -z kafka-3 29094; do
        sleep 5
      done
      echo 'Creating topics...'
      kafka-topics --bootstrap-server kafka-1:29092 --create --if-not-exists --topic logs --replication-factor 3 --partitions 5
      "
    networks:
      - stream_net
    deploy:
      restart_policy:
        condition: on-failure

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:29092,kafka-2:29093,kafka-3:29094
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - zookeeper
      - kafka-1
      - kafka-2
      - kafka-3
    networks:
      - stream_net

  # Database & Auth
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
      POSTGRES_DB: log_platform_db
    volumes:
      - db_data:/var/lib/postgresql/data
    deploy:
      replicas: 1
    networks:
      - data_net

  keycloak:
    image: quay.io/keycloak/keycloak:22.0
    command: start-dev --import-realm
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    volumes:
      - ./keycloak/realm-export.json:/opt/keycloak/data/import/realm-export.json
    ports:
      - "8080:8080"
    deploy:
      replicas: 1
    networks:
      - public_net
      - data_net

  # Dashboard API (Python)
  dashboard-backend:
    build: ./dashboard_service
    image: dashboard-service:v1
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      DATABASE_URL: postgresql://admin:password@postgres:5432/log_platform_db
      KEYCLOAK_URL: http://keycloak:8080/realms/log-realm
      CLIENT_ID: log-client
      CLIENT_SECRET: secret
      OPENSEARCH_HOST: opensearch
      OPENSEARCH_PORT: 9200
    ports:
      - "8000:8000"
    depends_on:
      - postgres
      - keycloak
      - opensearch
    deploy:
      replicas: 1
    networks:
      - public_net
      - data_net

  # Go Services (Generator, Ingestor, Consumer)
  log-ingestor:
    build: ./log-ingestor
    image: log-ingestor:latest
    deploy:
      replicas: 2
    environment:
      - KAFKA_BROKERS=kafka-1:29092,kafka-2:29093,kafka-3:29094
      - KAFKA_TOPIC=logs
      - SERVER_ADDR=:8080
    depends_on:
      - init-kafka
    command: 
      - sh
      - -c
      - |
        echo "Waiting for Kafka..."
        until nc -z kafka-1 29092; do sleep 2; done
        echo "Kafka is up!"
        ./log-ingestor
    networks:
      - stream_net

  log-generator:
    build: ./log-generator
    image: log-generator:latest
    ports:
      - "8081:8081"
    volumes:
      - ./log-generator/config.docker.yaml:/app/config.yaml
      - /etc/localtime:/etc/localtime:ro
    depends_on:
      - log-ingestor
    command: 
      - sh
      - -c 
      - |
        echo "Waiting for Log Ingestor..."
        until nc -z log-ingestor 8080; do sleep 2; done
        echo "Log Ingestor is up!"
        ./log-generator
    networks:
      - public_net
      - stream_net

  log-consumer:
    build: ./log-consumer
    image: log-consumer:latest
    deploy:
      replicas: 2
    environment:
      - KAFKA_BROKERS=kafka-1:29092,kafka-2:29093,kafka-3:29094
      - KAFKA_TOPIC=logs
      - KAFKA_GROUP_ID=log-consumer-group
      - OPENSEARCH_ADDR=http://opensearch:9200
    depends_on:
      - init-kafka
      - opensearch
    command: 
      - sh
      - -c 
      - |
        echo "Waiting for Kafka..."
        until nc -z kafka-1 29092; do sleep 2; done
        echo "Kafka is up!"
        echo "Waiting for OpenSearch..."
        until nc -z opensearch 9200; do sleep 2; done
        echo "OpenSearch is up!"
        ./log-consumer
    networks:
      - data_net
      - stream_net

  # Storage & Visualization
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - DISABLE_SECURITY_PLUGIN=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
      - "9600:9600"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cat/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    networks:
      - data_net

  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.11.0
    ports:
      - "5601:5601"
    environment:
      OPENSEARCH_HOSTS: '["http://opensearch:9200"]'
      DISABLE_SECURITY_DASHBOARDS_PLUGIN: "true"
    depends_on:
      - opensearch
    networks:
      - data_net
      - public_net

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    depends_on:
      - log-ingestor
    networks:
      - stream_net
      - monitoring_net

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - public_net
      - monitoring_net

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    ports:
      - "8088:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/run/containerd/containerd.sock:/var/run/containerd/containerd.sock:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - monitoring_net

networks:
  public_net:
    driver: overlay
  data_net:
    driver: overlay
  stream_net:
    driver: overlay
  monitoring_net:
    driver: overlay

volumes:
  zookeeper_data:
  zookeeper_log:
  kafka_data_1:
  kafka_data_2:
  kafka_data_3:
  db_data:
  opensearch_data:
